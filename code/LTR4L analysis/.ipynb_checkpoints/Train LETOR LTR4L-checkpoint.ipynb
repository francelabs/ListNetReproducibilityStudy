{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from itertools import product\n",
    "from script_maker import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LTR4L\n",
    "This library implements the ListNet algorithm. We will apply it on the LETOR dataset in order to compare its results with ours."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the paramers are modifiable. The only things we cannot change are:\n",
    "* The input layer activation function is set to \"Identity\" (linear)\n",
    "* There are no dropout function for the hidden layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to run LTR4L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LTR4L can be downloaded with the following link : https://github.com/LTR4L/ltr4l.git\n",
    "- Place the whole content of the repository in the \"ltr4l\" folder\n",
    "- Install ant : ```sudo apt-get install ant```\n",
    "- Download the ivy jar file with the following link : http://ant.apache.org/ivy/download.cgi\n",
    "- Place the jar file in the directory used by ant : /usr/share/ant/lib\n",
    "- Open a terminal in the \"ltr4l\" folder and run the following commands:\n",
    "    - ```ant ivy-bootstrap```\n",
    "    - ```ant clean package```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing the same results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LTR4L library doesn't implement any feature to set the seed used to initialize the Neural Networks. Therefore, by retraining the models the final results might be slightly different from what is written in the Desire paper.\n",
    "\n",
    "However, the models we used to get the results written in the Desire paper have been kept in this repository. To find the same results, don't run this code and directly pass to the prediction part."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTR4L for MQ2008 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=[100,500,1000]\n",
    "learning_rates=[0.001,0.075]\n",
    "mon=[0.01,0.1,0.3]\n",
    "out_act=['Identity','Sigmoid']\n",
    "number_hidden_layers = [0,1]\n",
    "hid_act= ['Identity','Sigmoid','ReLu']\n",
    "number_neurons = [15,46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "###When there is no hidden layer, there is no need to change the activation function\n",
    "###of the hidden layers or change the number of neurons\n",
    "if 0 in number_hidden_layers:\n",
    "    total_it = len(epochs)*len(learning_rates)*len(mon)*len(out_act)\n",
    "    total_it += len(epochs)*len(learning_rates)*len(mon)*len(out_act)*len(hid_act)\\\n",
    "    *(len(number_hidden_layers)-1)*len(number_neurons)\n",
    "else:\n",
    "    total_it = len(epochs)*len(learning_rates)*len(mon)*len(out_act)*len(hid_act)\\\n",
    "    *len(number_hidden_layers)*len(number_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create the configuration files to set the listnet's parameters for each run.\n",
    "\n",
    "data_fold = \"MQ2008\"\n",
    "Folds = [1,2,3,4,5]\n",
    "path_of_config = \"ltr4l/confs\"\n",
    "\n",
    "make_json_config_files(epochs, learning_rates, mon,\n",
    "                       out_act, hid_act, number_hidden_layers,\n",
    "                       number_neurons, data_fold, Folds,\n",
    "                       path_of_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the shell file to run the LTR4L algorithm to train our models\n",
    "\n",
    "path_of_script = \"LTR4L_run_MQ2008.sh\"\n",
    "\n",
    "make_train_script(total_it, Folds, data_fold, path_of_config, path_of_script)\n",
    "#os.system(path_of_script)\n",
    "###For unknown reasons, running the script through jupyter cannot capture the training time, it must be run \n",
    "###directly through the terminal for that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LTR4L for MQ2007 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=[100,500]\n",
    "learning_rates=[0.001,0.075]\n",
    "mon=[0.01,0.1,0.3]\n",
    "out_act=['Identity','Sigmoid']\n",
    "hid_act= ['Identity','Sigmoid','ReLu']\n",
    "number_hidden_layers = [0,1]\n",
    "number_neurons = [15,46]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When there is no hidden layer, there is no need to change the activation function\n",
    "#of the hidden layers or change the number of neurons\n",
    "if 0 in number_hidden_layers:\n",
    "    total_it = len(epochs)*len(learning_rates)*len(mon)*len(out_act)\n",
    "    total_it += len(epochs)*len(learning_rates)*len(mon)*len(out_act)*len(hid_act)\\\n",
    "    *(len(number_hidden_layers)-1)*len(number_neurons)\n",
    "else:\n",
    "    total_it = len(epochs)*len(learning_rates)*len(mon)*len(out_act)*len(hid_act)\\\n",
    "    *len(number_hidden_layers)*len(number_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Create the configuration files to set the listnet's parameters for each run.\n",
    "\n",
    "data_fold = \"MQ2007\"\n",
    "Folds = [1,2,3,4,5]\n",
    "path_of_config = \"ltr4l/confs\"\n",
    "\n",
    "make_json_config_files(epochs, learning_rates, mon,\n",
    "                       out_act, hid_act, number_hidden_layers,\n",
    "                       number_neurons, data_fold, Folds,\n",
    "                       path_of_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the shell file to run the LTR4L algorithm to train our models\n",
    "\n",
    "path_of_script = \"LTR4L_run_MQ2007.sh\"\n",
    "\n",
    "make_train_script(total_it, Folds, data_fold, path_of_config, path_of_script)\n",
    "#os.system(path_of_script)\n",
    "###For unknown reasons, running the script through jupyter cannot capture the training time, it must be run \n",
    "###directly through the terminal for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
